{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine generated datasets for training and testing\n",
    "\n",
    "In this notebook, we take the generated datasets for triangle singularity (2 loops) and poles (3 configurations) and combine them to create an input-output tuple readable by Chainer. We do this for both the training and testing datasets. We export them as ```chainer_train.pkl``` and ```chainer_test.pkl```. \n",
    "\n",
    "Note that for the training set, we apply a shuffling of the data. Specify the number of shuffling in ```NShuffle```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import chainer\n",
    "from chainer.dataset import convert\n",
    "\n",
    "# Select directory where datasets are stored\n",
    "directory = 'Datasets'\n",
    "out = directory\n",
    "\n",
    "# Set number to shuffle the dataset\n",
    "NShuffle = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the training datasets (2 triangle sets and 3 pole sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all inputs\n",
    "TSAin = pickle.load(open(os.path.join(out,'T00Ainputs_train.pkl'),'rb'))\n",
    "TSBin = pickle.load(open(os.path.join(out,'T00Binputs_train.pkl'),'rb'))\n",
    "P01in = pickle.load(open(os.path.join(out,'P01inputs_train.pkl'),'rb'))\n",
    "P02in = pickle.load(open(os.path.join(out,'P02inputs_train.pkl'),'rb'))\n",
    "P03in = pickle.load(open(os.path.join(out,'P03inputs_train.pkl'),'rb'))\n",
    "# Combine all the input training\n",
    "inputtraining = np.concatenate((TSAin,TSBin,P01in,P02in,P03in),axis=0)\n",
    "inputtraining = np.float32(np.asarray(inputtraining))\n",
    "\n",
    "# Get all outputs\n",
    "TSAout = pickle.load(open(os.path.join(out,'T00Aoutputs_train.pkl'),'rb'))\n",
    "TSBout = pickle.load(open(os.path.join(out,'T00Boutputs_train.pkl'),'rb'))\n",
    "P01out = pickle.load(open(os.path.join(out,'P01outputs_train.pkl'),'rb'))\n",
    "P02out = pickle.load(open(os.path.join(out,'P02outputs_train.pkl'),'rb'))\n",
    "P03out = pickle.load(open(os.path.join(out,'P03outputs_train.pkl'),'rb'))\n",
    "# Combine all the output training\n",
    "outputtraining = np.concatenate((TSAout,TSBout,P01out,P02out,P03out),axis=0)\n",
    "outputtraining = np.float32(np.asarray(outputtraining))\n",
    "outputtraining = outputtraining.astype(int)\n",
    "\n",
    "print('size of training set:', len(inputtraining))\n",
    "print('number of input nodes:', len(inputtraining[0]))\n",
    "\n",
    "# Shuffle the combined training inputs and outputs\n",
    "for ndx in range(NShuffle):\n",
    "    inputtraining, outputtraining = shuffle(inputtraining, outputtraining)\n",
    "\n",
    "# Create input-output tuples that can be read by Chainer\n",
    "chainer_train = chainer.datasets.TupleDataset(inputtraining, outputtraining)\n",
    "\n",
    "# Export the training set\n",
    "pickle.dump(chainer_train, open(os.path.join(out,'chainer_train.pkl'),'wb'), protocol=4)\n",
    "print('Done exporting!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the testing datasets (2 triangle sets and 3 pole sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all inputs:\n",
    "TSAin = pickle.load(open(os.path.join(out,'T00Ainputs_test.pkl'),'rb'))\n",
    "TSBin = pickle.load(open(os.path.join(out,'T00Binputs_test.pkl'),'rb'))\n",
    "P01in = pickle.load(open(os.path.join(out,'P01inputs_test.pkl'),'rb'))\n",
    "P02in = pickle.load(open(os.path.join(out,'P02inputs_test.pkl'),'rb'))\n",
    "P03in = pickle.load(open(os.path.join(out,'P03inputs_test.pkl'),'rb'))\n",
    "# Combine all the input testing\n",
    "inputtest = np.concatenate((TSAin,TSBin,P01in,P02in,P03in),axis=0)\n",
    "inputtest = np.float32(np.asarray(inputtest))\n",
    "\n",
    "# Get all outputs\n",
    "TSAout = pickle.load(open(os.path.join(out,'T00Aoutputs_test.pkl'),'rb'))\n",
    "TSBout = pickle.load(open(os.path.join(out,'T00Boutputs_test.pkl'),'rb'))\n",
    "P01out = pickle.load(open(os.path.join(out,'P01outputs_test.pkl'),'rb'))\n",
    "P02out = pickle.load(open(os.path.join(out,'P02outputs_test.pkl'),'rb'))\n",
    "P03out = pickle.load(open(os.path.join(out,'P03outputs_test.pkl'),'rb'))\n",
    "# Combine all the output testing\n",
    "outputtest = np.concatenate((TSAout,TSBout,P01out,P02out,P03out),axis=0)\n",
    "outputtest = np.float32(np.asarray(outputtest))\n",
    "outputtest = outputtest.astype(int)\n",
    "\n",
    "print('size of testing set:', len(inputtest))\n",
    "print('number of input nodes:', len(inputtest[0]))\n",
    "\n",
    "# No need to shuffle the combined testing inputs and outputs\n",
    "\n",
    "# Create input-output tuples that can be read by Chainer\n",
    "chainer_test = chainer.datasets.TupleDataset(inputtest, outputtest)\n",
    "\n",
    "# Export the testing set\n",
    "pickle.dump(chainer_test, open(os.path.join(out,'chainer_test.pkl'),'wb'), protocol=4)\n",
    "print('Done exporting!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
